{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b62e33-3bfd-4362-93d8-62af208379d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f460b0b-a902-493c-8307-6ac499ce7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "903e3d5e-9d5b-4c40-8373-a98c871ef8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import metrics \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2143a5e-8729-46c2-9182-bb3344431c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>UsingIP</th>\n",
       "      <th>LongURL</th>\n",
       "      <th>ShortURL</th>\n",
       "      <th>Symbol@</th>\n",
       "      <th>Redirecting//</th>\n",
       "      <th>PrefixSuffix-</th>\n",
       "      <th>SubDomains</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DomainRegLen</th>\n",
       "      <th>...</th>\n",
       "      <th>WebsiteForwarding</th>\n",
       "      <th>DisableRightClick</th>\n",
       "      <th>UsingPopupWindow</th>\n",
       "      <th>IframeRedirection</th>\n",
       "      <th>AgeofDomain</th>\n",
       "      <th>DNSRecording</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>LinksPointingToPage</th>\n",
       "      <th>StatsReport</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  UsingIP  LongURL  ShortURL  Symbol@  Redirecting//  PrefixSuffix-  \\\n",
       "0      0        1        1         1        1              1             -1   \n",
       "1      1        1        0         1        1              1             -1   \n",
       "2      2        1        0         1        1              1             -1   \n",
       "3      3        1        0        -1        1              1             -1   \n",
       "4      4       -1        0        -1        1             -1             -1   \n",
       "\n",
       "   SubDomains  HTTPS  DomainRegLen  ...  WebsiteForwarding  DisableRightClick  \\\n",
       "0           0      1            -1  ...                  0                  1   \n",
       "1          -1     -1            -1  ...                  0                  1   \n",
       "2          -1     -1             1  ...                  0                  1   \n",
       "3           1      1            -1  ...                  0                  1   \n",
       "4           1      1            -1  ...                  0                  1   \n",
       "\n",
       "   UsingPopupWindow  IframeRedirection  AgeofDomain  DNSRecording  PageRank  \\\n",
       "0                 1                  1           -1            -1        -1   \n",
       "1                 1                  1            1            -1        -1   \n",
       "2                 1                  1           -1            -1        -1   \n",
       "3                -1                  1           -1            -1        -1   \n",
       "4                 1                  1            1             1        -1   \n",
       "\n",
       "   LinksPointingToPage  StatsReport  class  \n",
       "0                    1            1     -1  \n",
       "1                    0           -1     -1  \n",
       "2                   -1            1     -1  \n",
       "3                    1            1      1  \n",
       "4                   -1           -1      1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Downloads/phishing2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64cffbd2-1741-476c-a78d-10f17ce21980",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"class\",\"Index\"],axis =1)\n",
    "Y = data[\"class\"]\n",
    "Y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d58619-068b-4103-b7f6-e95036acb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "train_X,test_X,train_Y,test_Y=train_test_split(X,Y, test_size = 0.3 ,random_state = 42)\n",
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix,classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b37520c4-b2e9-4766-b0e6-9fe10fa9b22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.7, max_depth=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.7, max_depth=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.7, max_depth=4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(max_depth=4,learning_rate=0.7)\n",
    "\n",
    "gbc.fit(train_X,train_Y)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df57a2c5-1c1d-4857-b11c-240164fbe39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_gbc = gbc.predict(train_X)\n",
    "y_test_gbc = gbc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c86635-5efa-44a9-b0ec-1dada63c9f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier : Accuracy on training Data: 0.953\n",
      "Gradient Boosting Classifier : Accuracy on test Data: 0.936\n",
      "\n",
      "Gradient Boosting Classifier : F1 score on training Data: 0.958\n",
      "Gradient Boosting Classifier : F1 score on test Data: 0.943\n",
      "\n",
      "Gradient Boosting Classifier :Recall on training Data: 0.960\n",
      "Gradient Boosting Classifier :Recall on testing Data: 0.950\n",
      "\n",
      "Gradient Boosting Classifier : Accuracy on training Data: 0.955\n",
      "Gradient Boosting Classifier : Accuracy on test Data: 0.937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_train_gbc = metrics.accuracy_score(train_Y,y_train_gbc)\n",
    "acc_test_gbc = metrics.accuracy_score(test_Y,y_test_gbc)\n",
    "print(\"Gradient Boosting Classifier : Accuracy on training Data: {:.3f}\".format(acc_train_gbc))\n",
    "print(\"Gradient Boosting Classifier : Accuracy on test Data: {:.3f}\".format(acc_test_gbc))\n",
    "print()\n",
    "\n",
    "f1_score_train_gbc = metrics.f1_score(train_Y,y_train_gbc)\n",
    "f1_score_test_gbc = metrics.f1_score(test_Y,y_test_gbc)\n",
    "\n",
    "print(\"Gradient Boosting Classifier : F1 score on training Data: {:.3f}\".format(f1_score_train_gbc))\n",
    "print(\"Gradient Boosting Classifier : F1 score on test Data: {:.3f}\".format(f1_score_test_gbc))\n",
    "print()\n",
    "\n",
    "recall_score_train_gbc = metrics.recall_score(train_Y,y_train_gbc)\n",
    "recall_score_test_gbc = metrics.recall_score(test_Y,y_test_gbc)\n",
    "print(\"Gradient Boosting Classifier :Recall on training Data: {:.3f}\".format(recall_score_train_gbc))\n",
    "print(\"Gradient Boosting Classifier :Recall on testing Data: {:.3f}\".format(recall_score_test_gbc))\n",
    "print()\n",
    "\n",
    "\n",
    "precision_score_train_gbc = metrics.precision_score(train_Y,y_train_gbc)\n",
    "precision_score_test_gbc = metrics.precision_score(test_Y,y_test_gbc)\n",
    "\n",
    "print(\"Gradient Boosting Classifier : Accuracy on training Data: {:.3f}\".format(precision_score_train_gbc))\n",
    "print(\"Gradient Boosting Classifier : Accuracy on test Data: {:.3f}\".format(precision_score_test_gbc))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971d377-f957-43be-8d31-b2747d2b0457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b62088db-1d9f-467d-b53f-2a592432d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import favicon\n",
    "import ipaddress\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "import requests\n",
    "import favicon\n",
    "import whois\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "from dateutil.parser import parse as date_parse\n",
    "from urllib.parse import urlparse\n",
    "import dns.resolver\n",
    "\n",
    "class FeatureExtraction:\n",
    "    features = []\n",
    "    def __init__(self,url):\n",
    "        self.features = []\n",
    "        self.url = url\n",
    "        self.domain = \"\"\n",
    "        self.whois_response = \"\"\n",
    "        self.urlparse = \"\"\n",
    "        self.response = \"\"\n",
    "        self.soup = \"\"\n",
    "\n",
    "        try:\n",
    "            self.response = requests.get(url)\n",
    "            self.soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.urlparse = urlparse(url)\n",
    "            self.domain = self.urlparse.netloc\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.whois_response = whois.whois(self.domain)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.features.append(self.UsingIp())\n",
    "        self.features.append(self.longUrl())\n",
    "        self.features.append(self.shortUrl())\n",
    "        self.features.append(self.symbol())\n",
    "        self.features.append(self.redirecting())\n",
    "        self.features.append(self.prefixSuffix())\n",
    "        self.features.append(self.SubDomains())\n",
    "        self.features.append(self.Https())\n",
    "        self.features.append(self.DomainRegLen())\n",
    "        self.features.append(self.Favicon())\n",
    "        \n",
    "\n",
    "        self.features.append(self.NonStdPort())\n",
    "        self.features.append(self.HTTPSDomainURL())\n",
    "        # self.features.append(self.RequestURL())\n",
    "        # self.features.append(self.AnchorURL())\n",
    "        # self.features.append(self.LinksInScriptTags())\n",
    "        self.features.append(self.ServerFormHandler())\n",
    "        self.features.append(self.InfoEmail())\n",
    "        self.features.append(self.AbnormalURL())\n",
    "        self.features.append(self.WebsiteForwarding())\n",
    "        # self.features.append(self.StatusBarCust())\n",
    "\n",
    "        self.features.append(self.DisableRightClick())\n",
    "        self.features.append(self.UsingPopupWindow())\n",
    "        self.features.append(self.IframeRedirection())\n",
    "        self.features.append(self.AgeofDomain())\n",
    "        self.features.append(self.DNSRecording())\n",
    "        # self.features.append(self.WebsiteTraffic())\n",
    "        self.features.append(self.PageRank())\n",
    "        # self.features.append(self.GoogleIndex())\n",
    "        self.features.append(self.LinksPointingToPage())\n",
    "        self.features.append(self.StatsReport())\n",
    "\n",
    "\n",
    "     # 1.UsingIp\n",
    "    def UsingIp(self):\n",
    "        try:\n",
    "            print('1')\n",
    "            ipaddress.ip_address(self.url)\n",
    "            return -1\n",
    "            print('-1')\n",
    "        except:\n",
    "            print('1')\n",
    "            return 1\n",
    "\n",
    "    # 2.longUrl\n",
    "    def longUrl(self):\n",
    "        print('2')\n",
    "        if len(self.url) < 54:\n",
    "            print('1')\n",
    "            return 1\n",
    "        if len(self.url) >= 54 and len(self.url) <= 75:\n",
    "            print('0')\n",
    "            return 0\n",
    "        else:\n",
    "            print('-1')\n",
    "            return -1\n",
    "\n",
    "    # 3.shortUrl\n",
    "    def shortUrl(self):\n",
    "        print('3')\n",
    "        match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                    'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                    'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                    'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                    'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                    'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                    'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net', self.url)\n",
    "        if match:\n",
    "            print('-1')\n",
    "            return -1\n",
    "        \n",
    "        else:\n",
    "            print('1')\n",
    "            return 1\n",
    "\n",
    "    # 4.Symbol@\n",
    "    def symbol(self):\n",
    "        print('4')\n",
    "        if re.findall(\"@\",self.url):\n",
    "            print('-1')\n",
    "            return -1\n",
    "        else:\n",
    "            print('1')\n",
    "            return 1\n",
    "    \n",
    "    # 5.Redirecting//\n",
    "    def redirecting(self):\n",
    "        print('5')\n",
    "        try:\n",
    "            response = requests.get(self.url, allow_redirects=False)\n",
    "            \n",
    "            if response.status_code in [301, 302]:\n",
    "                \n",
    "            # This indicates a redirect\n",
    "                redirect_count = len(response.history)\n",
    "            \n",
    "                if redirect_count > 6:\n",
    "                    print('-1')\n",
    "                    return -1  # More than 6 redirects, suspicious\n",
    "                else:\n",
    "                    print('1')\n",
    "                    return 1  # Less than or equal to 6 redirects\n",
    "\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1  # No redirect\n",
    "        except:\n",
    "            print(-1)\n",
    "            return -1  # Handle exceptions as potentially suspicious\n",
    "\n",
    "    \n",
    "    # 6.prefixSuffix\n",
    "    def prefixSuffix(self):\n",
    "        print('6')\n",
    "        try:\n",
    "            match = re.findall('\\-', self.domain)\n",
    "            if match:\n",
    "                print('-1')\n",
    "                return -1\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1\n",
    "        except:\n",
    "            return -1\n",
    "    \n",
    "    # 7.SubDomains\n",
    "    def SubDomains(self):\n",
    "        print('7')\n",
    "        dot_count = len(re.findall(\"\\.\", self.url))\n",
    "        if dot_count == 1:\n",
    "            print('1')\n",
    "            return 1\n",
    "        elif dot_count == 2:\n",
    "            print('0')\n",
    "            return 0\n",
    "        else:\n",
    "            print('-1')\n",
    "            return -1\n",
    "\n",
    "    \n",
    "    # def Hppts(self):\n",
    "    #     print('8')\n",
    "    #     try:\n",
    "    #         https = self.urlparse.scheme\n",
    "    #         if 'https' in https:\n",
    "    #             print('1')\n",
    "    #             return 1\n",
    "    #         else:\n",
    "    #             print('-1')\n",
    "    #             return -1\n",
    "    #     except:\n",
    "    #         print('1')\n",
    "    #         return 1\n",
    "\n",
    "    # 8.HTTPS\n",
    "    def Https(self):\n",
    "        print('8')\n",
    "        try:\n",
    "            response = requests.get(self.url)\n",
    "            if response.url.startswith('https'):\n",
    "                print('1')\n",
    "                return 1\n",
    "                \n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print('-1')\n",
    "            return -1\n",
    "\n",
    "\n",
    "    # 9.DomainRegLen\n",
    "    def DomainRegLen(self):\n",
    "        print('9')\n",
    "        try:\n",
    "            expiration_date = self.whois_response.expiration_date\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            try:\n",
    "                if(len(expiration_date)):\n",
    "                    expiration_date = expiration_date[0]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(len(creation_date)):\n",
    "                    creation_date = creation_date[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            age = (expiration_date.year-creation_date.year)*12+ (expiration_date.month-creation_date.month)\n",
    "            if age >=12:\n",
    "                print('1')\n",
    "                return 1\n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        except:\n",
    "            print('-1')\n",
    "            return -1\n",
    "            \n",
    "\n",
    "    \n",
    "    # def Favicon(self):\n",
    "    #     print('10')\n",
    "    #     try:\n",
    "    #         for head in self.soup.find_all('head'):\n",
    "    #             for head.link in self.soup.find_all('link', href=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', head.link['href'])]\n",
    "    #                 if self.url in head.link['href'] or len(dots) == 1 or domain in head.link['href']:\n",
    "    #                     print('1')\n",
    "    #                     return 1\n",
    "    #                 else:\n",
    "    #                     print('-1')\n",
    "    #                     return -1\n",
    "    #     except:\n",
    "    #         print('-1')\n",
    "    #         return -1\n",
    "\n",
    "\n",
    "    # # 10. Favicon\n",
    "    # def Favicon(self):\n",
    "    #     print('10')\n",
    "    #     try:\n",
    "    #         icons = Favicon.get(self)\n",
    "    #         if icons:\n",
    "    #             icon_url = icons[0].self\n",
    "    #             icon_response = requests.get(icon_url)\n",
    "                \n",
    "    #             # Check if the content is an image (you may refine this check if needed)\n",
    "    #             if 'image' in icon_response.headers['Content-Type']:\n",
    "    #                 print(1)\n",
    "    #                 return 1  # Recognizable favicon, indicating safe\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error while checking favicon: {e}\")\n",
    "    #         print('-1')\n",
    "    #         return -1  # Suspicious favicon or no favicon found\n",
    "\n",
    "\n",
    "\n",
    "    # 10. Favicon\n",
    "\n",
    "\n",
    "    def Favicon(self):\n",
    "        print('10')\n",
    "        try:\n",
    "            response = requests.get(self.url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                favicon_link = soup.find('link', rel='icon')\n",
    "                \n",
    "                if favicon_link and 'href' in favicon_link.attrs:\n",
    "                    favicon_url = favicon_link['href']\n",
    "                    if not favicon_url.startswith(('http:', 'https:')):\n",
    "                        # Construct the complete URL if it's a relative path\n",
    "                        favicon_url = url + favicon_url\n",
    "    \n",
    "                    # Check if the favicon URL points to an image\n",
    "                    favicon_response = requests.head(favicon_url)\n",
    "                    if 'image' in favicon_response.headers.get('Content-Type', ''):\n",
    "                        print('1')\n",
    "                        return 1\n",
    "            else:\n",
    "                print(-1)\n",
    "                return -1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while checking favicon: {e}\")\n",
    "            print(-1)\n",
    "            return -1\n",
    "        return -1\n",
    "\n",
    "    # 11. NonStdPort\n",
    "    def NonStdPort(self):\n",
    "        print('11')\n",
    "        try:\n",
    "            port = self.domain.split(\":\")\n",
    "            if len(port)>1:\n",
    "                print('-1')\n",
    "                return -1\n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        except:\n",
    "            print(-1)\n",
    "            return -1\n",
    "\n",
    "    \n",
    "      # 12. HTTPSDomainURL\n",
    "    def HTTPSDomainURL(self):\n",
    "        print('12')\n",
    "        try:\n",
    "            if 'https' in self.domain:\n",
    "                print('-1')\n",
    "                return -1\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1\n",
    "        except:\n",
    "            print('e-1')\n",
    "            return -1\n",
    "            \n",
    "    #  # 13. RequestURL\n",
    "    # def RequestURL(self):\n",
    "    #     print('13')\n",
    "    #     try:\n",
    "    #         if self.soup:\n",
    "    #             i, success = 0, 0\n",
    "    \n",
    "    #             for img in self.soup.find_all('img', src=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', img['src'])]\n",
    "    #                 if self.url in img['src'] or '.' not in img['src']:\n",
    "    #                     success += 1\n",
    "    #                 i += 1\n",
    "    \n",
    "    #             for audio in self.soup.find_all('audio', src=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', audio['src'])]\n",
    "    #                 if self.url in audio['src'] or '.' not in audio['src']:\n",
    "    #                     success += 1\n",
    "    #                 i += 1\n",
    "    \n",
    "    #             for embed in self.soup.find_all('embed', src=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', embed['src'])]\n",
    "    #                 if self.url in embed['src'] or '.' not in embed['src']:\n",
    "    #                     success += 1\n",
    "    #                 i += 1\n",
    "    \n",
    "    #             for iframe in self.soup.find_all('iframe', src=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', iframe['src'])]\n",
    "    #                 if self.url in iframe['src'] or '.' not in iframe['src']:\n",
    "    #                     success += 1\n",
    "    #                 i += 1\n",
    "    \n",
    "    #             try:\n",
    "    #                 percentage = (success / float(i)) * 100\n",
    "    #                 if percentage < 22.0:\n",
    "    #                     return 1  # Safe\n",
    "    #                 elif 22.0 <= percentage < 61.0:\n",
    "    #                     return 0  # Potentially Malware\n",
    "    #                 else:\n",
    "    #                     return -1  # Suspicious\n",
    "    #             except ZeroDivisionError:\n",
    "    #                 return -1  # Suspicious (division by zero)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error in RequestURL: {e}\")\n",
    "    #         return -1  # Suspicious (error occurred)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "    # # 14. AnchorURL\n",
    "    # def AnchorURL(self):\n",
    "    #     try:\n",
    "    #         print('anchor')\n",
    "    #         if self.soup:\n",
    "    #             i, unsafe = 0, 0\n",
    "    #             for a in self.soup.find_all('a', href=True):\n",
    "    #                 if \"#\" in a['href'] or \"javascript\" in a['href'].lower() or \"mailto\" in a['href'].lower() or \\\n",
    "    #                         not (self.url in a['href'] or '.' not in a['href']):\n",
    "    #                     unsafe += 1\n",
    "    #                 i += 1\n",
    "\n",
    "    #             try:\n",
    "    #                 percentage = (unsafe / float(i)) * 100\n",
    "    #                 if percentage < 31.0:\n",
    "    #                     return 1  # Safe\n",
    "    #                 elif 31.0 <= percentage < 67.0:\n",
    "    #                     return 0  # Potentially Malware\n",
    "    #                 else:\n",
    "    #                     return -1  # Suspicious\n",
    "    #             except ZeroDivisionError:\n",
    "    #                 return -1  # Suspicious (division by zero)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error in AnchorURL: {e}\")\n",
    "    #         return -1  # Suspicious (error occurred)\n",
    "\n",
    "\n",
    "    #  # 15. LinksInScriptTags\n",
    "    # def LinksInScriptTags(self):\n",
    "    #     try:\n",
    "    #         if self.soup:\n",
    "    #             i, success = 0, 0\n",
    "    #             for link in self.soup.find_all('link', href=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', link['href'])]\n",
    "    #                 if self.url in link['href'] or '.' not in link['href']:\n",
    "    #                     success += 1\n",
    "    #                 i += 1\n",
    "\n",
    "    #             for script in self.soup.find_all('script', src=True):\n",
    "    #                 dots = [x.start(0) for x in re.finditer('\\.', script['src'])]\n",
    "    #                 if self.url in script['src'] or '.' not in script['src']:\n",
    "    #                     success += 1\n",
    "    #                 i += 1\n",
    "\n",
    "    #             try:\n",
    "    #                 percentage = (success / float(i)) * 100\n",
    "    #                 if percentage < 17.0:\n",
    "    #                     return 1  # Safe\n",
    "    #                 elif 17.0 <= percentage < 81.0:\n",
    "    #                     return 0  # Potentially Malware\n",
    "    #                 else:\n",
    "    #                     return -1  # Suspicious\n",
    "    #             except ZeroDivisionError:\n",
    "    #                 return -1  # Suspicious (division by zero)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error in LinksInScriptTags: {e}\")\n",
    "    #         return -1  # Suspicious (error occurred)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # 16. ServerFormHandler\n",
    "    def ServerFormHandler(self):\n",
    "        print('16')\n",
    "        try:\n",
    "            if len(self.soup.find_all('form', action=True))==0:\n",
    "                print('1')\n",
    "                return 1\n",
    "            else :\n",
    "                for form in self.soup.find_all('form', action=True):\n",
    "                    if form['action'] == \"\" or form['action'] == \"about:blank\":\n",
    "                        print('-1')\n",
    "                        return -1\n",
    "                    else:\n",
    "                        print('1')\n",
    "                        return 1\n",
    "        except:\n",
    "            print('e-1')\n",
    "            return -1\n",
    "\n",
    "    # 17. InfoEmail\n",
    "    def InfoEmail(self):\n",
    "        print('17')\n",
    "        try:\n",
    "            if re.findall(r\"[mail\\(\\)|mailto:?]\", self.soup):\n",
    "                print('-1')\n",
    "                return -1\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1\n",
    "        except:\n",
    "            print('e-1')\n",
    "            return -1\n",
    "\n",
    "    \n",
    "    # 18. AbnormalURL\n",
    "    def AbnormalURL(self):\n",
    "        print('18')\n",
    "        try:\n",
    "            if self.response.status_code != 200:\n",
    "            # If the HTTP status code is not 200 (OK), it might indicate an issue with the webpage\n",
    "                print('-1')\n",
    "                return -1\n",
    "        \n",
    "        # Check if the content length is unusually short\n",
    "            if len(self.response.text) < 100:\n",
    "                print('-1')\n",
    "                return -1\n",
    "\n",
    "        # Compare the HTML content with the WHOIS response\n",
    "            if self.response.text != self.whois_response.text:\n",
    "                return -1\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return -1\n",
    "\n",
    "    # 19. WebsiteForwarding\n",
    "    def WebsiteForwarding(self):\n",
    "        print('19')\n",
    "        try:\n",
    "            if len(self.response.history) <= 1:\n",
    "                print('1')\n",
    "                return 1\n",
    "            elif len(self.response.history) <= 4:\n",
    "                print('0')\n",
    "                return 0\n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        except:\n",
    "             return -1\n",
    "\n",
    "    # # 20. StatusBarCust\n",
    "    # def StatusBarCust(self):\n",
    "    #     print('20')\n",
    "    #     try:\n",
    "    #         if re.findall(\"<script>.+onmouseover.+</script>\", self.response.text):\n",
    "    #             print('1')\n",
    "    #             return 1\n",
    "                \n",
    "    #         else:\n",
    "    #             print('1')\n",
    "    #             return -1\n",
    "               \n",
    "    #     except:\n",
    "    #          return -1\n",
    "\n",
    "    # 21. DisableRightClick\n",
    "    def DisableRightClick(self):\n",
    "        print('21')\n",
    "        try:\n",
    "            if re.findall(r\"event.button ?== ?2\", self.response.text):\n",
    "                return -1\n",
    "                print('-1')\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1\n",
    "        except:\n",
    "             return -1\n",
    "\n",
    "    # 22. UsingPopupWindow\n",
    "    def UsingPopupWindow(self):\n",
    "        print('22')\n",
    "        try:\n",
    "            if re.findall(r\"alert\\(\", self.response.text):\n",
    "                print('-1')\n",
    "                return -1  \n",
    "            else:\n",
    "                print(1)\n",
    "                return 1  \n",
    "        except Exception as e:\n",
    "            print(f\"Error in UsingPopupWindow: {e}\")\n",
    "            return -1\n",
    "\n",
    "\n",
    "    # 23. IframeRedirection\n",
    "\n",
    "\n",
    "    def IframeRedirection(self):\n",
    "        print('23')\n",
    "        try:\n",
    "            if re.findall(r\"<iframe>|<frameBorder>\", self.response.text):\n",
    "                print('1')\n",
    "                return 1\n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error in IframeRedirection: {e}\")\n",
    "            print('-1')\n",
    "            return -1\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # def IframeRedirection(self):\n",
    "    #     print('23')\n",
    "    #     try:\n",
    "    #         print('try')\n",
    "    #         if re.findall(r\"<iframe>|<frameBorder>\", self.response.text): \n",
    "    #             print('-1')\n",
    "    #             return -1\n",
    "    #         else:\n",
    "    #             return('1')\n",
    "    #             return 1\n",
    "    #     except:\n",
    "    #         print('-1')\n",
    "    #         return -1\n",
    "\n",
    "    # 24. AgeofDomain\n",
    "\n",
    "    def AgeofDomain(self):\n",
    "        print('24')\n",
    "        try:\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            # if creation_date and len(creation_date) > 0:  \n",
    "            #     creation_date = creation_date[0]\n",
    "            today = date.today()\n",
    "            age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "            if age >= 6:\n",
    "                print('1')\n",
    "                return 1  \n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error in AgeofDomain: {e}\")\n",
    "            return -1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # def DNSRecording(self):\n",
    "    #     print('25')\n",
    "    #     try:\n",
    "    #         creation_date = self.whois_response.creation_date\n",
    "    #         try:\n",
    "    #             if(len(creation_date)):\n",
    "    #                 creation_date = creation_date[0]\n",
    "    #         except:\n",
    "    #             pass\n",
    "\n",
    "    #         today  = date.today()\n",
    "    #         age = (today.year-creation_date.year)*12+(today.month-creation_date.month)\n",
    "    #         if age >=6:\n",
    "    #             return 1\n",
    "    #         return -1\n",
    "    #     except:\n",
    "    #         return -1\n",
    "\n",
    "\n",
    "# 25. DNSRecording\n",
    "\n",
    "    \n",
    "    def DNSRecording(self):\n",
    "        print('25')\n",
    "        try:\n",
    "            answers = dns.resolver.query(self, 'A')\n",
    "            if answers:\n",
    "                print('1')\n",
    "                return 1  \n",
    "        except:\n",
    "            print('-1')\n",
    "            return -1  \n",
    "        \n",
    "    \n",
    "    # # Example usage\n",
    "    # domain = \"example.com\"\n",
    "    # result = check_dns_records(domain)\n",
    "    \n",
    "    # if result == 1:\n",
    "    #     print(f\"The domain {domain} has valid DNS records.\")\n",
    "    # elif result == -1:\n",
    "    #     print(f\"No DNS record found for the domain {domain}.\")\n",
    "    # else:\n",
    "    #     print(f\"Error occurred while querying DNS for the domain {domain}.\")\n",
    "\n",
    "\n",
    "    \n",
    "    # 26. WebsiteTraffic   \n",
    "    # def WebsiteTraffic(self):\n",
    "    #     print('26')\n",
    "    #     try:\n",
    "    #         rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n",
    "    #         if (int(rank) < 100000):\n",
    "    #             print('1')\n",
    "    #             return 1\n",
    "    #         return 0\n",
    "    #     except :\n",
    "    #         print('-1')\n",
    "    #         return -1\n",
    "\n",
    "    \n",
    "    # def PageRank(self):\n",
    "    #     print('27')\n",
    "    #     try:\n",
    "    #         prank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\"name\": self.domain})\n",
    "\n",
    "    #         global_rank = int(re.findall(r\"Global Rank: ([0-9]+)\", rank_checker_response.text)[0])\n",
    "    #         if global_rank > 0 and global_rank < 100000:\n",
    "    #             print('1')\n",
    "    #             return 1\n",
    "    #         return -1\n",
    "    #     except:\n",
    "    #         print('-1')\n",
    "    #         return -1\n",
    "# 27. PageRank\n",
    "    def PageRank(self):\n",
    "        print('27')\n",
    "        print(self.url)\n",
    "        \n",
    "        headers = {'API-OPR': '04ogocowc8c8g484sow0ccsg8o8gss048ggsccck'}\n",
    "        urls = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' +self.url\n",
    "        response = requests.get(urls, headers=headers)\n",
    "        result = response.json()\n",
    "\n",
    "# Extracting values from the JSON response\n",
    "        status_code = result['status_code']\n",
    "        if status_code ==200:\n",
    "            response_data = result['response']\n",
    "            for entry in response_data:\n",
    "                status_code_entry = entry['status_code']\n",
    "                error = entry['error']\n",
    "                page_rank_integer = entry['page_rank_integer']\n",
    "                page_rank_decimal = entry['page_rank_decimal']\n",
    "                rank = entry['rank']\n",
    "                domain_entry = entry['domain']\n",
    "                if status_code_entry==400:\n",
    "                    print('-1')\n",
    "                    return -1\n",
    "                if page_rank_integer==\"\" or page_rank_decimal==\"\" or rank==\"\":\n",
    "                    print('no-1')\n",
    "                    return -1\n",
    "                else:\n",
    "                    print('1')\n",
    "                    return 1\n",
    "        else:\n",
    "            print('e-1');\n",
    "            return -1\n",
    "\n",
    "            \n",
    "\n",
    "    # # 28. GoogleIndex\n",
    "    # def GoogleIndex(self):\n",
    "    #     print('28')\n",
    "    #     try:\n",
    "    #         site = search(self.url, 5)\n",
    "    #         if site:\n",
    "    #             print('1')\n",
    "    #             return 1\n",
    "    #         else:\n",
    "    #             print('-1')\n",
    "    #             return -1\n",
    "    #     except:\n",
    "    #         print('e-1')\n",
    "    #         return 1\n",
    "\n",
    "    # 29. LinksPointingToPage\n",
    "    def LinksPointingToPage(self):\n",
    "        print('29')\n",
    "        try:\n",
    "            number_of_links = len(re.findall(r\"<a href=\", self.response.text))\n",
    "            if number_of_links == 0:\n",
    "                print('1')\n",
    "                return 1\n",
    "            elif number_of_links <= 2:\n",
    "                print('0')\n",
    "                return 0\n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 30. StatsReport\n",
    "    def StatsReport(self):\n",
    "        print('30')\n",
    "        try:\n",
    "            url_match = re.search(\n",
    "        'at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly', url)\n",
    "            ip_address = socket.gethostbyname(self.domain)\n",
    "            ip_match = re.search('146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|'\n",
    "                                '107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|'\n",
    "                                '118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|'\n",
    "                                '216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|'\n",
    "                                '34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|'\n",
    "                                '216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42', ip_address)\n",
    "            if url_match:\n",
    "                print('-1')\n",
    "                return -1\n",
    "            elif ip_match:\n",
    "                print('ip -1')\n",
    "                return -1\n",
    "            else:\n",
    "                print(1)\n",
    "                return 1\n",
    "        except:\n",
    "            return 1\n",
    "    \n",
    "    def getFeaturesList(self):\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1483fc2b-5309-41ca-ae45-aa1ab27e6032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "-1\n",
      "5\n",
      "1\n",
      "6\n",
      "1\n",
      "7\n",
      "-1\n",
      "8\n",
      "1\n",
      "9\n",
      "1\n",
      "10\n",
      "-1\n",
      "11\n",
      "-1\n",
      "12\n",
      "1\n",
      "16\n",
      "e-1\n",
      "17\n",
      "1\n",
      "18\n",
      "-1\n",
      "19\n",
      "1\n",
      "21\n",
      "1\n",
      "22\n",
      "1\n",
      "23\n",
      "-1\n",
      "24\n",
      "-1\n",
      "25\n",
      "-1\n",
      "27\n",
      "\thttps://michal.miloszkrmze.pl/girlskackzorowski/email@example.com...\n",
      "-1\n",
      "29\n",
      "1\n",
      "30\n",
      "1\n",
      "We guess it is a safe website\n"
     ]
    }
   ],
   "source": [
    "url=\"\thttps://michal.miloszkrmze.pl/girlskackzorowski/email@example.com...\"\n",
    "#can provide any URL. this URL was taken from PhishTank\n",
    "obj = FeatureExtraction(url)\n",
    "x = np.array(obj.getFeaturesList()).reshape(1,24) \n",
    "y_pred =gbc.predict(x)[0]\n",
    "if y_pred==1:\n",
    "  print(\"We guess it is a safe website\")\n",
    "else:\n",
    "  print(\"Caution! Suspicious website detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd2bac-dd8a-40c8-b10d-5c095d6ca3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ff6c6-f873-465d-be1d-af7a48b96af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c5fa6-2473-4ef2-9b15-79a03539673a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa72ca0-bc6c-4a05-8171-1395850d8514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb1fdf-55f0-4560-98a3-b5143ce841ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def check_https(url):\n",
    "    print('hi')\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.url.startswith('https'):\n",
    "            print('1')\n",
    "            return 1\n",
    "            \n",
    "        else:\n",
    "            print('-1')\n",
    "            return -1\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print('-1')\n",
    "        return -1\n",
    "\n",
    "web='https://www.facebook.com'\n",
    "http=check_https(web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807bc297-7286-4eba-a865-d73a1cea82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# def check_https(url):\n",
    "#     print('hi')\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         if response.url.startswith('https'):\n",
    "#             print('1')\n",
    "#             return 1\n",
    "            \n",
    "#         else:\n",
    "#             print('-1')\n",
    "#             return -1\n",
    "            \n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "#         print('-1')\n",
    "#         return -1\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def PageRank(url):\n",
    "    print('27')\n",
    "    try:\n",
    "        prank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\"name\": url})\n",
    "        print (prank_checker_response)\n",
    "        global_rank = int(re.findall(r\"Global Rank: ([0-9]+)\", prank_checker_response.text)[0])\n",
    "        print (global_rank)\n",
    "        if 0 < global_rank < 100000:\n",
    "            print('1')\n",
    "            return 1\n",
    "        else:\n",
    "            print(-1)\n",
    "            return -1\n",
    "    except Exception as e:\n",
    "        print(f\"Error in PageRank: {e}\")\n",
    "        return -1\n",
    "\n",
    "# Example usage:\n",
    "url = \"www.facebook.com\"\n",
    "pagerank = PageRank(url)\n",
    "print(pagerank)\n",
    "\n",
    "\n",
    "\n",
    "# if is_https:\n",
    "#     print(f\"The website {url} uses HTTPS.\")\n",
    "# else:\n",
    "#     print(f\"The website {url} does not use HTTPS.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823be9f2-87f4-452d-9592-931fc83b2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_rank(url):\n",
    "    response = requests.get(f\"https://www.similarweb.com/website/{url}\")\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    rank_element = soup.findall('div', class_='wa-rank-list__value-container')\n",
    "    print(rank_element)\n",
    "    \n",
    "    if rank_element:\n",
    "        rank = rank_element.text.strip()\n",
    "        return rank\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "input_url = 'facebook.com'\n",
    "rank = get_rank(input_url)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f\"The rank of {input_url} is: {rank}\")\n",
    "else:\n",
    "    print(f\"The rank of {input_url} could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c915fb-c009-4f33-bdde-309cffd8576b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0010e-45ac-47d4-aff2-149ad40d6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_rank_from_external(url):\n",
    "    try:\n",
    "        response = requests.post('https://', data={'url': url})\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            rank_element = soup.find('p', class_='wa-rank-list__value')\n",
    "            \n",
    "            if rank_element:\n",
    "                rank = rank_element.text.strip()\n",
    "                return rank\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error: Unable to fetch data. Status code {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "url = 'https://.com' \n",
    "rank = get_rank_from_external(url)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f\"The rank of {url} is: {rank}\")\n",
    "else:\n",
    "    print(f\"The rank of {url} could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224cfe37-a80a-46e8-924b-cb06434590b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_traffic(url):\n",
    "    try:\n",
    "        response = requests.get(f'https://www.similarweb.com/{url}')\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        traffic = soup.find('div', {'class': 'engagement-value'}).text\n",
    "        print('1')\n",
    "        return traffic\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "url = 'facebook.com'\n",
    "print(get_traffic(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302b915-debd-405a-b6d9-2b41a29a103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://similarweb.com'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    # Process content with BeautifulSoup\n",
    "else:\n",
    "    print(f'Error: Unable to fetch data. Status code {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ac311-dba9-4abd-8234-631a60d12aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL where you want to make the POST request\n",
    "url = 'https://www.similarweb.com/'\n",
    "\n",
    "# Define the data you want to send in the POST request\n",
    "data = {\n",
    "    'param1': 'value1',\n",
    "    'param2': 'value2',\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, data=data)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print('POST request successful!')\n",
    "    print('Response:', response.text)\n",
    "else:\n",
    "    print('Error in POST request. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86825e36-8b2e-429c-8c5b-78861f9bcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_rank(url):\n",
    "    response = requests.get(\"https://www.thehoth.com/search-engine-rankings\")\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all the elements with class \"ranking\"\n",
    "    rankings = soup.find_all(\"div\", class_=\"ranking\")\n",
    "\n",
    "    for ranking in rankings:\n",
    "        website_element = ranking.find(\"div\", class_=\"col-md-4 col-sm-4 col-xs-12 website\")\n",
    "        if website_element and website_element.text.strip() == url:\n",
    "            rank = int(re.search(r\"\\d+\", ranking.find(\"div\", class_=\"col-md-4 col-sm-4 col-xs-12 hoth-ranking\").text).group())\n",
    "            return rank\n",
    "\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://www.example.com\"  # Replace with the URL you want to check\n",
    "rank = get_rank(url)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f\"The rank of {url} is {rank}\")\n",
    "else:\n",
    "    print(f\"The rank of {url} could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b959c-4145-407a-af4a-60e73252c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_rank(url):\n",
    "    response = requests.get(\"https://www.similarweb.com\")\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "           if rank == soup.find(\"p\", class_=\"wa-rank-list__value\"):\n",
    "               print('hi')\n",
    "               print('1')\n",
    "               return 1\n",
    "    except:\n",
    "        print('-1')\n",
    "        return -1\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "url = \"https://facebook.com\"  # Replace with the URL you want to check\n",
    "rank = get_rank(url)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f\"The rank of {url} is {rank}\")\n",
    "else:\n",
    "    print(f\"The rank of {url} could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4fc24-2a6a-45ef-b73d-2752cf3e8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_rank(url):\n",
    "   \n",
    "    response =  requests.get(f'https://www.similarweb.com/{url}')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        rank_element = soup.find(\"p\", class_=\"wa-rank-list__value\")\n",
    "        if rank_element:\n",
    "            print('1')\n",
    "            return 1\n",
    "    except:\n",
    "        print('-1')\n",
    "        return -1\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://www.facebook.com\"  # Replace with the URL you want to check\n",
    "rank = get_rank(url)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f\"The rank of {url} is {rank}\")\n",
    "else:\n",
    "    print(f\"The rank of {url} could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582a476-49e1-4a29-be48-636e5a83de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import favicon\n",
    "import requests\n",
    "\n",
    "def check_favicon(url):\n",
    "    try:\n",
    "        icons = favicon.get(url)\n",
    "        if icons:\n",
    "            icon_url = icons[0].url\n",
    "            icon_response = requests.get(icon_url)\n",
    "            \n",
    "            # Check if the content is an image (you may refine this check if needed)\n",
    "            if 'image' in icon_response.headers['Content-Type']:\n",
    "                print(1)\n",
    "                return 1  # Recognizable favicon, indicating safe\n",
    "    except Exception as e:\n",
    "        print(f\"Error while checking favicon: {e}\")\n",
    "        print('-1')\n",
    "        return -1  # Suspicious favicon or no favicon found\n",
    "\n",
    "# Example usage\n",
    "result = check_favicon(\"https://www.facebook.com\")\n",
    "print(result)  # Output: 1 (Assuming https://www.example.com has a recognizable favicon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239d260-b33c-437f-aa7a-3efea31404f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088903ee-2f0c-4d20-85f0-943f7a796256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from favicon import Favicon\n",
    "\n",
    "def check_favicon(url):\n",
    "    try:\n",
    "        icons = Favicon.get(url)\n",
    "        if icons:\n",
    "            icon_url = icons[0].url\n",
    "            icon_response = requests.get(icon_url)\n",
    "            \n",
    "            # Check if the content is an image (you may refine this check if needed)\n",
    "            if 'image' in icon_response.headers['Content-Type']:\n",
    "                return 1  # Recognizable favicon, indicating safe\n",
    "    except Exception as e:\n",
    "        print(f\"Error while checking favicon: {e}\")\n",
    "    \n",
    "    return -1  # Suspicious favicon or no favicon found.\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://facebook.com\"\n",
    "result = check_favicon(url)\n",
    "\n",
    "if result == 1:\n",
    "    print(f\"The favicon for {url} is recognizable, indicating safe.\")\n",
    "else:\n",
    "    print(f\"The favicon for {url} is suspicious or not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78902182-ae9f-4c61-ad6a-21d9c7b9603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def has_recognizable_favicon(url):\n",
    "        print('10')\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                favicon_link = soup.find('link', rel='icon')\n",
    "                \n",
    "                if favicon_link and 'href' in favicon_link.attrs:\n",
    "                    favicon_url = favicon_link['href']\n",
    "                    if not favicon_url.startswith(('http:', 'https:')):\n",
    "                        # Construct the complete URL if it's a relative path\n",
    "                        favicon_url = url + favicon_url\n",
    "    \n",
    "                    # Check if the favicon URL points to an image\n",
    "                    favicon_response = requests.head(favicon_url)\n",
    "                    if 'image' in favicon_response.headers.get('Content-Type', ''):\n",
    "                        print('1')\n",
    "                        return 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while checking favicon: {e}\")\n",
    "            print(-1)\n",
    "            return -1\n",
    "\n",
    "# Example usage:\n",
    "url = \"\thttps://facebook.com\"\n",
    "if has_recognizable_favicon(url):\n",
    "    print(f\"The website {url} has a recognizable favicon.\")\n",
    "else:\n",
    "    print(f\"The website {url} does not have a recognizable favicon.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a822c-4b82-4722-bae9-52a73af6e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AgeofDomain(website):\n",
    "    print('24')\n",
    "    try:\n",
    "        creation_date = website.whois_response.creation_date\n",
    "\n",
    "        if creation_date:\n",
    "            if isinstance(creation_date, list):\n",
    "                creation_date = creation_date[0]\n",
    "\n",
    "            today = date.today()\n",
    "            age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "\n",
    "            if age >= 6:\n",
    "                print('1')\n",
    "                return 1\n",
    "            else:\n",
    "                print('-1')\n",
    "                return -1\n",
    "        else:\n",
    "            print('-1')\n",
    "            return -1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in AgeofDomain: {e}\")\n",
    "        return -1\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://facebook.com\"\n",
    "AgeofDomain(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc645524-a256-4ea1-acb8-16bbc5f0721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_similarweb_rank(api_key, website):\n",
    "    url = f'https://api.similarweb.com/v1/website/{website}/global-rank/global?api_key={api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        rank = data['GlobalRank']['Rank']\n",
    "        return rank\n",
    "    else:\n",
    "        print(f'Error: {response.status_code}')\n",
    "        return None\n",
    "\n",
    "# Get the API key and website from the user\n",
    "api_key = input('kugisaki ')\n",
    "website = input('facebook.com ')\n",
    "\n",
    "# Call the function to get the SimilarWeb rank\n",
    "rank = get_similarweb_rank(api_key, website)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f'The SimilarWeb rank of {website} is: {rank}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076ab93-04ca-460a-82be-b8d63cbd6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_similarweb_rank(api_key, website):\n",
    "    url = f'https://api.similarweb.com/v1/similar-rank/{website}/rank?api_key={api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        rank = data['GlobalRank']['Rank']\n",
    "        return rank\n",
    "    else:\n",
    "        print(f'Error: {response.status_code}')\n",
    "        return None\n",
    "\n",
    "# Get the API key and website from the user\n",
    "api_key = input('kugisaki ')\n",
    "website = input('facebook.com')\n",
    "\n",
    "# Call the function to get the SimilarWeb rank\n",
    "rank = get_similarweb_rank(api_key, website)\n",
    "\n",
    "if rank is not None:\n",
    "    print(f'The SimilarWeb rank of {website} is: {rank}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0599ac6-3b91-4dd2-bb50-b0326158e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = 'kugisaki'\n",
    "website_url = 'facebook.com'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'website': website_url\n",
    "}\n",
    "\n",
    "response = requests.post('https://www.similarweb.com/', headers=headers, data=json.dumps(data))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    global_rank = response.json()['global_rank']\n",
    "    print(f'The global rank of {website_url} is {global_rank}.')\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756df2d-27f8-44b6-8ef1-cf3906e22431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the website you want to scrape\n",
    "url = \"http://www.facebook.com\"\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Now you can use BeautifulSoup to navigate and extract data\n",
    "    # For example, let's find all the links on the page\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    for link in links:\n",
    "        print(link.get('href'))\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to fetch data. Status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f079d-3223-4983-b322-45c569853691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def PageRank(domain):\n",
    "    try:\n",
    "        rank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\"name\": domain})\n",
    "\n",
    "        global_rank = int(re.findall(r\"Domain Analysis For: ([0-9]+)\", rank_checker_response.text)[0])\n",
    "        if 0 < global_rank < 100000:\n",
    "            print('1')\n",
    "            return 1\n",
    "        else:\n",
    "            print('-1')\n",
    "            return -1\n",
    "    except:\n",
    "        print('e-1')\n",
    "        return -1\n",
    "\n",
    "url = 'facebook.com'\n",
    "rank = PageRank(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d703c-81df-4b59-bff1-c33072959f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8573fb-d7b6-4a14-98b9-319ad9beaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the website you want to search\n",
    "url = \"http://www.checkpagerank.net\"  # Replace with the actual URL\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Check if the text is present in the response content\n",
    "    if \"facebook\" in response.text:\n",
    "        print(\"Found the text in the website.\")\n",
    "    else:\n",
    "        print(\"Text not found in the website.\")\n",
    "else:\n",
    "    print(f\"Error: Unable to fetch data. Status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04aa1b80-e2ed-445b-b46d-15b8fceea9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': False, 'error': 'Invalid API key '}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "headers = {'API-OPR':'cogo4gko8oc4so48oso0s8w8wsgg0g0kk4g8c40k'}\n",
    "domain = 'google.com'\n",
    "url = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' + domain\n",
    "request = requests.get(url, headers=headers)\n",
    "result = request.json()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41316de5-8595-43e0-a72c-1a946f640805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'status_code': 200, 'response': [{'status_code': 400, 'error': 'Invalid Domain', 'page_rank_integer': '', 'page_rank_decimal': '', 'rank': '', 'domain': 'addgames.awardspace.biz/'}], 'last_updated': '17th Mar 2023'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "headers = {'API-OPR':'04ogocowc8c8g484sow0ccsg8o8gss048ggsccck'}\n",
    "domain = 'https://addgames.awardspace.biz/'\n",
    "url = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' + domain\n",
    "request = requests.get(url, headers=headers)\n",
    "result = request.json()\n",
    "\n",
    "if result:\n",
    "    print('1')\n",
    "else:\n",
    "    print('-1')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a496d9f-8d7a-45e3-8ab8-63c007de4ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "{'status_code': 200, 'response': [{'status_code': 400, 'error': 'Invalid Domain', 'page_rank_integer': '', 'page_rank_decimal': '', 'rank': '', 'domain': 'addgames.awardspace.biz/'}], 'last_updated': '17th Mar 2023'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the headers and domain\n",
    "headers = {'API-OPR': '04ogocowc8c8g484sow0ccsg8o8gss048ggsccck'}\n",
    "domain = 'https://addgames.awardspace.biz/'\n",
    "\n",
    "# Construct the API URL\n",
    "url = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' + domain\n",
    "\n",
    "# Send the GET request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    result = response.json()\n",
    "    \n",
    "    # Access the data you need (in this case, 'status_code')\n",
    "    status_code = result['status_code']\n",
    "    \n",
    "    # Check the status code\n",
    "    if status_code != 200:\n",
    "        print('-1')\n",
    "    else:\n",
    "        print('1')\n",
    "else:\n",
    "    print('-1')\n",
    "\n",
    "# Print the full result (for debugging)\n",
    "print()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac284b68-e205-4218-98cd-e88b9637c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Status Code: 200\n",
      "Last Updated: 17th Mar 2023\n",
      "Status Code: 404\n",
      "\n",
      "Response Data:\n",
      "Status Code: 404, Error: Domain not found, Page Rank (Integer): 0, Page Rank (Decimal): 0, Rank: None, Domain: michal.miloszkrmze.pl\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {'API-OPR': '04ogocowc8c8g484sow0ccsg8o8gss048ggsccck'}\n",
    "domain = 'michal.miloszkrmze.pl'\n",
    "url = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' + domain\n",
    "response = requests.get(url, headers=headers)\n",
    "result = response.json()\n",
    "\n",
    "# Extracting values from the JSON response\n",
    "status_code = result['status_code']\n",
    "response_data = result['response']\n",
    "\n",
    "# Accessing data from each response entry\n",
    "for entry in response_data:\n",
    "    status_code_entry = entry['status_code']\n",
    "    error = entry['error']\n",
    "    page_rank_integer = entry['page_rank_integer']\n",
    "    page_rank_decimal = entry['page_rank_decimal']\n",
    "    rank = entry['rank']\n",
    "    domain_entry = entry['domain']\n",
    "    if status_code_entry==400:\n",
    "        print('-1')\n",
    "    if page_rank_integer==\"\" or page_rank_decimal==\"\" or rank==\"\":\n",
    "        print('no-1')\n",
    "    else:\n",
    "        print('1')\n",
    "\n",
    "# Accessing last_updated\n",
    "last_updated = result['last_updated']\n",
    "\n",
    "# Print or use the variables as needed\n",
    "print(\"Status Code:\", status_code)\n",
    "print(\"Last Updated:\", last_updated)\n",
    "print(\"Status Code:\", status_code_entry )\n",
    "print(\"\\nResponse Data:\")\n",
    "for entry in response_data:\n",
    "    print(f\"Status Code: {entry['status_code']}, Error: {entry['error']}, Page Rank (Integer): {entry['page_rank_integer']}, Page Rank (Decimal): {entry['page_rank_decimal']}, Rank: {entry['rank']}, Domain: {entry['domain']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ba9adfd-ba69-4466-9e2c-4f046339fbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "hi-1\n",
      "no-1\n",
      "Status Code: 200\n",
      "Last Updated: 17th Mar 2023\n",
      "Status Code: 400\n",
      "\n",
      "Response Data:\n",
      "Status Code: 400, Error: Invalid Domain, Page Rank (Integer): , Page Rank (Decimal): , Rank: , Domain: michal.miloszkrmze.pl/girlskackzorowski/email@example.com...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print('27')\n",
    "headers = {'API-OPR': '04ogocowc8c8g484sow0ccsg8o8gss048ggsccck'}\n",
    "url = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' +domain\n",
    "response = requests.get(url, headers=headers)\n",
    "result = response.json()\n",
    "\n",
    "# Extracting values from the JSON response\n",
    "status_code = result['status_code']\n",
    "if status_code ==200:\n",
    "    response_data = result['response']\n",
    "    for entry in response_data:\n",
    "        status_code_entry = entry['status_code']\n",
    "        error = entry['error']\n",
    "        page_rank_integer = entry['page_rank_integer']\n",
    "        page_rank_decimal = entry['page_rank_decimal']\n",
    "        rank = entry['rank']\n",
    "        domain_entry = entry['domain']\n",
    "        if status_code_entry==400:\n",
    "            print('hi-1')\n",
    "            \n",
    "        if page_rank_integer==\"\" or page_rank_decimal==\"\" or rank==\"\":\n",
    "            print('no-1')\n",
    "            \n",
    "        else:\n",
    "            print('1')\n",
    "            \n",
    "else:\n",
    "    print('e-1');\n",
    "    \n",
    "\n",
    "# Accessing last_updated\n",
    "last_updated = result['last_updated']\n",
    "\n",
    "# Print or use the variables as needed\n",
    "print(\"Status Code:\", status_code)\n",
    "print(\"Last Updated:\", last_updated)\n",
    "print(\"Status Code:\", status_code_entry )\n",
    "print(\"\\nResponse Data:\")\n",
    "for entry in response_data:\n",
    "    print(f\"Status Code: {entry['status_code']}, Error: {entry['error']}, Page Rank (Integer): {entry['page_rank_integer']}, Page Rank (Decimal): {entry['page_rank_decimal']}, Rank: {entry['rank']}, Domain: {entry['domain']}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c9365762-2bcd-4f9f-aca3-ec7c245e7d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PageRank() missing 1 required positional argument: 'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 35\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mPageRank\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://michal.miloszkrmze.pl/girlskackzorowski/email@example.com...\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: PageRank() missing 1 required positional argument: 'url'"
     ]
    }
   ],
   "source": [
    "def PageRank(self, url):\n",
    "    print('27')\n",
    "    print(url)\n",
    "\n",
    "    headers = {'API-OPR': '04ogocowc8c8g484sow0ccsg8o8gss048ggsccck'}\n",
    "    full_url = f'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D={url}'\n",
    "    response = requests.get(full_url, headers=headers)\n",
    "    result = response.json()\n",
    "\n",
    "    # Extracting values from the JSON response\n",
    "    status_code = result['status_code']\n",
    "    if status_code == 200:\n",
    "        response_data = result['response']\n",
    "        for entry in response_data:\n",
    "            status_code_entry = entry['status_code']\n",
    "            error = entry['error']\n",
    "            page_rank_integer = entry['page_rank_integer']\n",
    "            page_rank_decimal = entry['page_rank_decimal']\n",
    "            rank = entry['rank']\n",
    "            domain_entry = entry['domain']\n",
    "            if status_code_entry == 400:\n",
    "                print('-1')\n",
    "                return -1\n",
    "            if page_rank_integer == \"\" or page_rank_decimal == \"\" or rank == \"\":\n",
    "                print('no-1')\n",
    "                return -1\n",
    "            else:\n",
    "                print('1')\n",
    "                return 1\n",
    "    else:\n",
    "        print('e-1')\n",
    "        return -1\n",
    "\n",
    "\n",
    "result = PageRank('https://michal.miloszkrmze.pl/girlskackzorowski/email@example.com...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cdfef-0ff0-4e51-b9ce-bfaa23c149b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
